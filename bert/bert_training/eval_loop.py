# -*- coding: utf-8 -*-
"""eval_loop.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ofqzbfkwnFPu-DuVejszmVRrXhlEmkHv
"""

import torch

def test_step(model: torch.nn.Module,
              dataloader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module,
              device):

    # Put the model in eval mode
    model.eval()

    # Setup test loss and test accuracy values
    test_loss, test_acc = 0, 0

    # Turn on inference context manager
    with torch.inference_mode():
        # Loop through DataLoader batches
        for batch in dataloader:

            if isinstance(batch, (list, tuple)) and len(batch) == 3:
                input_ids, attention_mask, labels = batch
            else:
                input_ids = batch["input_ids"]
                attention_mask = batch["attention_mask"]
                segment_ids = batch["segment_ids"].to(device)
                labels = batch["labels"]
            
            input_ids = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            segment_ids = batch["segment_ids"].to(device)
            labels = batch["labels"].to(device)

            # 1. Forward pass
            test_pred_logits = model(input_ids, segment_ids=segment_ids)

            # 2. Calculate and accumulate loss
            loss = loss_fn(test_pred_logits, labels)
            test_loss += loss.item()

            # Calculate and accumulate accuracy
            test_pred_labels = test_pred_logits.argmax(dim=1)
            test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))

    # Adjust metrics to get average loss and accuracy per batch
    test_loss = test_loss / len(dataloader)
    test_acc = test_acc / len(dataloader)
    return test_loss, test_acc